{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Zookeeper and Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZooKeeper JMX enabled by default\r\n",
      "Using config: /usr/local/etc/zookeeper/zoo.cfg\r\n",
      "Starting zookeeper ... already running as process 7632.\r\n"
     ]
    }
   ],
   "source": [
    "# need to first get Zookeeper up and running\n",
    "! zkServer start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-03-02 21:22:08,671] INFO Verifying properties (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,711] INFO Property broker.id is overridden to 0 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,711] INFO Property log.cleaner.enable is overridden to false (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,711] INFO Property log.dirs is overridden to /usr/local/var/lib/kafka-logs (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,711] INFO Property log.retention.check.interval.ms is overridden to 300000 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,712] INFO Property log.retention.hours is overridden to 168 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,712] INFO Property log.segment.bytes is overridden to 1073741824 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,712] INFO Property num.io.threads is overridden to 8 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,712] INFO Property num.network.threads is overridden to 3 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,713] INFO Property num.partitions is overridden to 1 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,713] INFO Property num.recovery.threads.per.data.dir is overridden to 1 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,713] INFO Property port is overridden to 9092 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,713] INFO Property socket.receive.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,713] INFO Property socket.request.max.bytes is overridden to 104857600 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,714] INFO Property socket.send.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,714] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,714] INFO Property zookeeper.connection.timeout.ms is overridden to 6000 (kafka.utils.VerifiableProperties)\n",
      "[2016-03-02 21:22:08,790] INFO [Kafka Server 0], starting (kafka.server.KafkaServer)\n",
      "[2016-03-02 21:22:08,795] INFO [Kafka Server 0], Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)\n",
      "[2016-03-02 21:22:08,809] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)\n",
      "[2016-03-02 21:22:08,841] INFO Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,841] INFO Client environment:host.name=10.0.0.15 (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,841] INFO Client environment:java.version=1.8.0_66 (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,841] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,841] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_66.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,841] INFO Client environment:java.class.path=:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/jopt-simple-3.2.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/log4j-1.2.16.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/lz4-1.2.0.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/metrics-core-2.2.0.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/scala-library-2.10.4.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/slf4j-api-1.7.6.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/slf4j-log4j12-1.7.6.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/snappy-java-1.1.1.7.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/zkclient-0.3.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/dependant-libs-2.10.4/zookeeper-3.4.6.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../examples/build/libs//kafka-examples-0.8.2.2.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../contrib/hadoop-consumer/build/libs//kafka-hadoop-consumer-0.8.2.2.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../contrib/hadoop-producer/build/libs//kafka-hadoop-producer-0.8.2.2.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../clients/build/libs/kafka-clients-0.8.2.2.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../libs/*.jar:/usr/local/Cellar/kafka/0.8.2.2/libexec/bin/../core/build/libs/kafka_2.10-0.8.2.2.jar (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,842] INFO Client environment:java.library.path=/Users/LucasRamadan/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,842] INFO Client environment:java.io.tmpdir=/var/folders/t8/4df679b51r7cl7dm_68wbxgh0000gn/T/ (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,842] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,842] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,849] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,850] INFO Client environment:os.version=10.11.3 (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,850] INFO Client environment:user.name=LucasRamadan (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,850] INFO Client environment:user.home=/Users/LucasRamadan (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,850] INFO Client environment:user.dir=/Users/LucasRamadan/DSCI6007-student/Final-Project (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,852] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@429bd883 (org.apache.zookeeper.ZooKeeper)\n",
      "[2016-03-02 21:22:08,895] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)\n",
      "[2016-03-02 21:22:09,020] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)\n",
      "[2016-03-02 21:22:09,075] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1532973052e0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)\n",
      "[2016-03-02 21:22:09,078] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)\n",
      "[2016-03-02 21:22:09,165] INFO Loading logs. (kafka.log.LogManager)\n",
      "[2016-03-02 21:22:09,172] INFO Logs loading complete. (kafka.log.LogManager)\n",
      "[2016-03-02 21:22:09,173] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)\n",
      "[2016-03-02 21:22:09,177] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)\n",
      "[2016-03-02 21:22:09,213] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)\n",
      "[2016-03-02 21:22:09,214] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer)\n",
      "[2016-03-02 21:22:09,318] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)\n",
      "[2016-03-02 21:22:09,388] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)\n",
      "[2016-03-02 21:22:09,512] INFO Registered broker 0 at path /brokers/ids/0 with address 10.0.0.15:9092. (kafka.utils.ZkUtils$)\n",
      "[2016-03-02 21:22:09,531] INFO [Kafka Server 0], started (kafka.server.KafkaServer)\n",
      "[2016-03-02 21:22:09,607] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)\n",
      "^C[2016-03-02 21:22:53,950] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)\n",
      "[2016-03-02 21:22:53,952] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)\n",
      "\n",
      "[2016-03-02 21:22:54,034] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)\n",
      "[2016-03-02 21:22:54,041] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)\n",
      "[2016-03-02 21:22:54,081] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)\n",
      "[2016-03-02 21:22:54,082] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)\n",
      "[2016-03-02 21:22:54,084] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)\n"
     ]
    }
   ],
   "source": [
    "# then start the kafka server\n",
    "! kafka-server-start.sh /usr/local/etc/kafka/server.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the consumer to listen\n",
    "bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the twitter stream to pipe into the producer\n",
    "python ~/DSCI6007-student/Final-Project/simple_twitter_streaming.py | bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Kafka Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kafka\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x109008090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KafkaUtils.createStream?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "  Spark Streaming's Kafka libraries not found in class path. Try one of the following.\n",
      "\n",
      "  1. Include the Kafka library and its dependencies with in the\n",
      "     spark-submit command as\n",
      "\n",
      "     $ bin/spark-submit --packages org.apache.spark:spark-streaming-kafka:1.6.0 ...\n",
      "\n",
      "  2. Download the JAR of the artifact from Maven Central http://search.maven.org/,\n",
      "     Group Id = org.apache.spark, Artifact Id = spark-streaming-kafka-assembly, Version = 1.6.0.\n",
      "     Then, include the jar in the spark-submit command as\n",
      "\n",
      "     $ bin/spark-submit --jars <spark-streaming-kafka-assembly.jar> ...\n",
      "\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o21.loadClass.\n: java.lang.ClassNotFoundException: org.apache.spark.streaming.kafka.KafkaUtilsPythonHelper\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9ebbb030dcaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKafkaUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'localhost:2181'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.6.0/libexec/python/pyspark/streaming/kafka.py\u001b[0m in \u001b[0;36mcreateStream\u001b[0;34m(ssc, zkQuorum, groupId, topics, kafkaParams, storageLevel, keyDecoder, valueDecoder)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'ClassNotFoundException'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mKafkaUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_printErrorMsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPairDeserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNoOpSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoOpSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o21.loadClass.\n: java.lang.ClassNotFoundException: org.apache.spark.streaming.kafka.KafkaUtilsPythonHelper\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "k = KafkaUtils.createStream(ssc, 'localhost:2181', 1, {'test':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
